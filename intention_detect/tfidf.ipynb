{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ckiptagger import WS\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"IVR\"\n",
    "WS_SET = [\"jieba\", \"ckip\", \"mix_0\", \"mix_1\"]\n",
    "WORD_SEGMENTER = WS_SET[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf(corpus, voc, idf):\n",
    "    count_vectorizer = CountVectorizer(vocabulary=voc, token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "    tf = count_vectorizer.fit_transform(corpus)\n",
    "    tfidf = (np.ma.log(tf.toarray()) + 1) * idf\n",
    "    tfidf = tfidf.filled(0)\n",
    "    \n",
    "    return normalize(tfidf, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(test_tfidf, train_tfidf, num_labels=None):\n",
    "    if num_labels is None:\n",
    "        sim_array = cosine_similarity(test_tfidf, train_tfidf)\n",
    "    else:\n",
    "        train_tfidf_by_class = []\n",
    "        start_idx = 0\n",
    "        for i in num_labels:\n",
    "            train_tfidf_by_class += [train_tfidf[start_idx : start_idx+i].mean(axis=0)]\n",
    "            start_idx += i\n",
    "        train_tfidf_by_class = np.stack(train_tfidf_by_class)\n",
    "        sim_array = cosine_similarity(test_tfidf, train_tfidf_by_class)\n",
    "    \n",
    "    return np.array(sim_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(sim_array, test_data, train_data, sim_mode):\n",
    "    correct = 0\n",
    "    for i, ans in enumerate(test_data[\"label\"]):\n",
    "        if sim_mode == 0:\n",
    "            sorted_arg = np.argsort(sim_array[i])\n",
    "            sorted_arg = np.flip(sorted_arg)[:10] # 10 for top 10 similar\n",
    "            sorted_pred = [train_data[\"label\"][idx] for idx in sorted_arg]\n",
    "            pred = max(set(sorted_pred), key=sorted_pred.count)\n",
    "        else:\n",
    "            pred = np.argmax(sim_array[i])\n",
    "    \n",
    "        if pred == ans:\n",
    "            correct += 1\n",
    "    acc = correct / len(test_data[\"label\"])\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7fad43471630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7fad43471630>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7fad43471978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7fad43471978>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7fad4340b748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7fad4340b748>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7fad4340bc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7fad4340bc88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fad44e045c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fad44e045c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "if WORD_SEGMENTER == \"ckip\" or WORD_SEGMENTER.find(\"mix\") != -1:\n",
    "    ws = WS(\"../ckiptagger/data\")\n",
    "\n",
    "def get_model_data(file_path):\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "    df = df.sort_values(by=[\"labels\"], ignore_index=True)\n",
    "    src_labels = sorted(set(df.labels.tolist()))\n",
    "    df[\"labels\"] = [src_labels.index(l) for l in df.labels.tolist()]\n",
    "    texts = df[\"texts\"]\n",
    "    labels = df[\"labels\"]\n",
    "    num_labels = list(Counter(labels).values())\n",
    "    \n",
    "    data = {\"corpus\":[], \"label\":[], \"src_texts\":[], \"src_label\":[]}\n",
    "    \n",
    "    for i, t in (enumerate(texts)):\n",
    "        label = labels[i]\n",
    "        \n",
    "        if WORD_SEGMENTER == \"ckip\":\n",
    "            sentence_seg = ws([t])[0]\n",
    "        elif WORD_SEGMENTER == \"jieba\":\n",
    "            sentence_seg = jieba.lcut(t)\n",
    "        elif WORD_SEGMENTER == \"mix_0\":\n",
    "            temp = ws([t])[0]\n",
    "            sentence_seg = []\n",
    "            for seg_t in temp:\n",
    "                sentence_seg += jieba.lcut(seg_t)\n",
    "        elif WORD_SEGMENTER == \"mix_1\":\n",
    "            temp = jieba.lcut(t)\n",
    "            sentence_seg = []\n",
    "            for seg_t in temp:\n",
    "                sentence_seg += ws([seg_t])[0]\n",
    "    \n",
    "        sentence_seg = [seg_t for seg_t in sentence_seg if seg_t!=' ']\n",
    "        seg_texts = ' '.join(sentence_seg)\n",
    "        \n",
    "        data[\"corpus\"] += [seg_texts]\n",
    "        data[\"label\"] += [label]\n",
    "        data[\"src_texts\"] += [t]\n",
    "        data[\"src_label\"] += [src_labels[label]]\n",
    "    return data, num_labels # Dict[List], List[Int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.680 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "286it [00:14, 19.82it/s]\n"
     ]
    }
   ],
   "source": [
    "data_train, num_labels = get_model_data(f\"data/{DATASET}/train.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "82it [00:05, 15.58it/s]\n"
     ]
    }
   ],
   "source": [
    "data_test, _ = get_model_data(f\"data/{DATASET}/test.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(286, 557)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "train_tfidf = tfidf_vectorizer.fit_transform(data_train[\"corpus\"])\n",
    "idf = tfidf_vectorizer.idf_\n",
    "voc_list = tfidf_vectorizer.get_feature_names()\n",
    "print(train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82, 557)\n"
     ]
    }
   ],
   "source": [
    "test_tfidf = get_tfidf(data_test[\"corpus\"], voc_list, idf)\n",
    "print(test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82, 286)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8658536585365854"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SIM_MODE = 0\n",
    "sim_array = get_similarity(test_tfidf, train_tfidf)\n",
    "print(sim_array.shape)\n",
    "get_prediction(sim_array, data_test, data_train, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82, 41)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9512195121951219"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SIM_MODE = 1\n",
    "sim_array = get_similarity(test_tfidf, train_tfidf, num_labels)\n",
    "print(sim_array.shape)\n",
    "get_prediction(sim_array, data_test, data_train, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc = [\"卡\", \"卡片\"]\n",
    "corpus = [\"我的卡片多少錢\", \"account activate\"]\n",
    "count_vectorizer = CountVectorizer(vocabulary=voc, token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "tf = count_vectorizer.fit_transform(corpus)\n",
    "tf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
