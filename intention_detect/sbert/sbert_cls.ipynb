{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b84437",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install transformers\n",
    "!pip install tqdm\n",
    "# from IPython.display import clear_output\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56b95409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AdamW\n",
    "from sentence_transformers import models, InputExample, SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe4770d",
   "metadata": {},
   "source": [
    "## Hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8449e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "tokenizer_LM = \"../bert-base-chinese\"\n",
    "NO = 1\n",
    "LM_SET = [\"../bert-base-chinese\", \"../ckiplab/bert-base-chinese\", \"../hfl/chinese-bert-wwm\", \"../hfl/rbtl3\"]\n",
    "MODEL_NAME_SET = [\"base\", \"ckip\", \"wwm\", \"rbtl3\"]\n",
    "LM = LM_SET[NO]\n",
    "MODEL_NAME = f\"sbert_cls_{MODEL_NAME_SET[NO]}\"\n",
    "\n",
    "DATASET = \"SMP2018\"\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "TEST_BATCH_SIZE = 64\n",
    "MODEL_PATH = f\"model/sbert_cls_{DATASET}/{MODEL_NAME}\" # svae/load model name/path\n",
    "EPOCHS = 10\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device=\"cpu\"\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e35739",
   "metadata": {},
   "source": [
    "## Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46aded6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime,timezone,timedelta\n",
    "def timestamp(msg=\"\"):\n",
    "    dt1 = datetime.utcnow().replace(tzinfo=timezone.utc)\n",
    "    dt2 = dt1.astimezone(timezone(timedelta(hours=8))) # 轉換時區 -> 東八區\n",
    "    print(str(dt2)[:-13] + '\\t' + msg)\n",
    "    return (str(dt2)[:-13] + '\\t' + msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92c1d0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# high-level 顯示此模型裡的 modules\n",
    "def model_info(model):\n",
    "#     print(model.device)\n",
    "    print(\"\"\"\n",
    "    name            module\n",
    "    ----------------------\"\"\")\n",
    "    for name, module in model.named_children():\n",
    "        if name == \"bert\" or name==\"0\":\n",
    "            for n, _ in module.named_children():\n",
    "                print(f\"{name}:{n}\")\n",
    "    #             print(_)\n",
    "        else:\n",
    "            print(\"{:15} {}\".format(name, module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cb454c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d0c47d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emb_visualize(bert_model):\n",
    "    df = pd.read_csv(f\"data/{DATASET}/train.tsv\", sep='\\t')\n",
    "    # assert len(dataloader.dataset) == df.shape[0]\n",
    "    df = df.sort_values(by=\"labels\", ignore_index=True)\n",
    "    # _, emb = get_predictions(model, trainLoader, compute_acc=False, get_emb=True)\n",
    "    emb = bert_model.encode(df[\"texts\"].tolist(), convert_to_numpy=True)\n",
    "    low_dim_emb = TSNE(n_components=2, perplexity=30).fit_transform(emb)\n",
    "\n",
    "    df[\"f1\"] = low_dim_emb[:, 0]\n",
    "    df[\"f2\"] = low_dim_emb[:, 1]\n",
    "    emb_fig = sns.relplot(\n",
    "        data=df, x=\"f1\", y=\"f2\",\n",
    "        hue=\"labels\", alpha=0.7,\n",
    "        kind=\"scatter\")\n",
    "    emb_by_cls_fig = sns.relplot(\n",
    "        data=df, x=\"f1\", y=\"f2\",\n",
    "        col=\"labels\", col_wrap=4,\n",
    "        kind=\"scatter\")\n",
    "    return emb_fig, emb_by_cls_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36045f9c",
   "metadata": {},
   "source": [
    "## Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79dbcf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_data(mode, file_path):\n",
    "    assert mode in [\"train\", \"test\", \"dev\"]\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "    df = df.sort_values(by=[\"labels\"], ignore_index=True)\n",
    "    src_labels = sorted(set(df.labels.tolist()))\n",
    "    num_labels = len(src_labels)\n",
    "    df[\"labels\"] = [src_labels.index(l) for l in df.labels.tolist()]\n",
    "\n",
    "    bert_data = []\n",
    "    texts = df[\"texts\"]\n",
    "    labels = df[\"labels\"]\n",
    "    for i, t in enumerate(texts):\n",
    "        label = labels[i]\n",
    "        bert_dict = {\"texts\":t, \"label\":label}\n",
    "        bert_data += [bert_dict]\n",
    "        \n",
    "    if mode == \"train\":\n",
    "        return bert_data, num_labels #List[Dict[List]] = List[tokenizer output]\n",
    "    else:\n",
    "        return bert_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6d185f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2299 31\n"
     ]
    }
   ],
   "source": [
    "\"\"\"training data\"\"\"\n",
    "bert_train, num_labels = get_bert_data(\"train\", f\"data/{DATASET}/train.tsv\")\n",
    "print(len(bert_train), num_labels)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3665ac40",
   "metadata": {},
   "source": [
    "\"\"\"devlopment data\"\"\"\n",
    "bert_dev = get_bert_data(\"dev\", f\"data/{DATASET}/valid.tsv\")\n",
    "len(bert_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0818cb8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "770"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"testing data\"\"\"\n",
    "bert_test = get_bert_data(\"test\", f\"data/{DATASET}/test.tsv\")\n",
    "len(bert_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b028efca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "class intent_Dataset(Dataset):\n",
    "    def __init__(self, list_of_bert):\n",
    "        self.data = list_of_bert\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data[idx][\"texts\"]\n",
    "        label = self.data[idx][\"label\"]\n",
    "        return text, label\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27602eef",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46d8431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class intent_classifier(nn.Module):\n",
    "    def __init__(self, LM, num_labels):\n",
    "        super().__init__()\n",
    "        bert = models.Transformer(LM, max_seq_length=128)\n",
    "        hidden_size = bert.get_word_embedding_dimension()\n",
    "        pooler = models.Pooling(hidden_size)\n",
    "        self.bert_model = SentenceTransformer(modules=[bert, pooler])\n",
    "        self.drop_out = nn.Dropout(0.1)\n",
    "        self.cls = nn.Linear(hidden_size, num_labels)\n",
    "        \n",
    "    def forward(self, \n",
    "                src_texts):\n",
    "        utterance_embedding = self.bert_model.encode(src_texts, convert_to_tensor=True)\n",
    "        intent_cls = self.drop_out(utterance_embedding)\n",
    "        intent_cls = self.cls(intent_cls)\n",
    "        \n",
    "        return dotdict(\n",
    "            utterance_emb=utterance_embedding, # batch_size * encoder_hidden_size\n",
    "            intent_cls=intent_cls) # batch_size * num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3358956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = intent_classifier(LM, num_labels=num_labels)\n",
    "optimizer = AdamW(model.parameters(), lr=3e-5) # AdamW = BertAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b3fc6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    name            module\n",
      "    ----------------------\n",
      "bert_model      SentenceTransformer(\n",
      "  (0): Transformer(\n",
      "    (auto_model): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (1): Pooling()\n",
      ")\n",
      "drop_out        Dropout(p=0.1, inplace=False)\n",
      "cls             Linear(in_features=768, out_features=31, bias=True)\n"
     ]
    }
   ],
   "source": [
    "model_info(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec943005",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet = intent_Dataset(bert_train)\n",
    "trainLoader = DataLoader(trainSet, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "testSet = intent_Dataset(bert_test)\n",
    "testLoader = DataLoader(testSet, batch_size=TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf3e800",
   "metadata": {},
   "source": [
    "## Train & validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08cc64ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, dataloader, compute_acc=False):\n",
    "    predictions = None\n",
    "    correct = 0\n",
    "    total = 0\n",
    "      \n",
    "    with torch.no_grad():\n",
    "        # 遍巡整個資料集\n",
    "        for data in tqdm(dataloader):\n",
    "            texts, labels = [t for t in data]\n",
    "            \n",
    "            outputs = model(texts)\n",
    "            \n",
    "            logits = outputs.intent_cls\n",
    "            _, pred = torch.max(logits.data, 1) # _: logits最大數值; pred: 最大數值的 index\n",
    "            \n",
    "            # 用來計算訓練集的分類準確率\n",
    "            if compute_acc:\n",
    "                total += labels.size(0)\n",
    "                correct += (pred == labels.to(device)).sum().item()\n",
    "                \n",
    "            # 將當前 batch 記錄下來\n",
    "            if predictions is None:\n",
    "                predictions = pred\n",
    "            else:\n",
    "                predictions = torch.cat((predictions, pred))\n",
    "    \n",
    "    if compute_acc:\n",
    "        acc = correct / total\n",
    "        return predictions, acc\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8573314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"tensorboard logger\"\"\"\n",
    "writer = SummaryWriter(f\"runs/{DATASET}/{MODEL_NAME}/E_{EPOCHS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ca35d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5/144 [00:00<00:02, 49.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-30 13:59:50\tstart training model/sbert_cls_SMP2018/sbert_cls_ckip from epoch 1 to 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:02<00:00, 58.19it/s]\n",
      "  5%|▍         | 7/144 [00:00<00:02, 61.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-30 13:59:52\t[epoch 1] loss: 475.414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:02<00:00, 62.87it/s]\n",
      " 15%|█▌        | 2/13 [00:00<00:00, 17.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] training acc: 0.193562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 24.43it/s]\n",
      "  4%|▍         | 6/144 [00:00<00:02, 54.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] testing acc: 0.198701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:02<00:00, 59.62it/s]\n",
      "  5%|▍         | 7/144 [00:00<00:02, 61.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-30 13:59:58\t[epoch 2] loss: 430.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:02<00:00, 62.42it/s]\n",
      " 15%|█▌        | 2/13 [00:00<00:00, 17.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] training acc: 0.277947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 24.40it/s]\n",
      "  4%|▍         | 6/144 [00:00<00:02, 56.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] testing acc: 0.280519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:02<00:00, 58.56it/s]\n",
      "  5%|▍         | 7/144 [00:00<00:02, 61.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-30 14:00:03\t[epoch 3] loss: 395.930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:02<00:00, 63.22it/s]\n",
      " 15%|█▌        | 2/13 [00:00<00:00, 17.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] training acc: 0.313180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 24.38it/s]\n",
      "  5%|▍         | 7/144 [00:00<00:02, 61.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] testing acc: 0.307792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:02<00:00, 59.02it/s]\n",
      "  5%|▍         | 7/144 [00:00<00:02, 60.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-30 14:00:08\t[epoch 4] loss: 370.041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:02<00:00, 62.44it/s]\n",
      " 15%|█▌        | 2/13 [00:00<00:00, 17.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] training acc: 0.343193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 24.47it/s]\n",
      "  4%|▍         | 6/144 [00:00<00:02, 53.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] testing acc: 0.331169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:02<00:00, 59.76it/s]\n",
      "  5%|▍         | 7/144 [00:00<00:02, 62.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-30 14:00:13\t[epoch 5] loss: 348.784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:02<00:00, 62.37it/s]\n",
      " 15%|█▌        | 2/13 [00:00<00:00, 17.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] training acc: 0.373641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 23.69it/s]\n",
      "  4%|▍         | 6/144 [00:00<00:02, 56.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] testing acc: 0.372727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:02<00:00, 59.54it/s]\n",
      "  5%|▍         | 7/144 [00:00<00:02, 62.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-30 14:00:19\t[epoch 6] loss: 329.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:02<00:00, 62.08it/s]\n",
      " 15%|█▌        | 2/13 [00:00<00:00, 17.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] training acc: 0.414093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 24.29it/s]\n",
      "  4%|▍         | 6/144 [00:00<00:02, 57.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] testing acc: 0.420779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:02<00:00, 60.29it/s]\n",
      "  5%|▍         | 7/144 [00:00<00:01, 68.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-30 14:00:24\t[epoch 7] loss: 311.404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:02<00:00, 62.69it/s]\n",
      " 15%|█▌        | 2/13 [00:00<00:00, 17.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7] training acc: 0.461940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 24.40it/s]\n",
      "  5%|▍         | 7/144 [00:00<00:02, 65.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7] testing acc: 0.445455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:02<00:00, 59.49it/s]\n",
      "  5%|▍         | 7/144 [00:00<00:02, 62.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-30 14:00:29\t[epoch 8] loss: 295.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:02<00:00, 62.53it/s]\n",
      " 15%|█▌        | 2/13 [00:00<00:00, 17.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8] training acc: 0.501522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 24.09it/s]\n",
      "  4%|▍         | 6/144 [00:00<00:02, 53.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8] testing acc: 0.487013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:02<00:00, 59.90it/s]\n",
      "  5%|▍         | 7/144 [00:00<00:02, 63.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-30 14:00:34\t[epoch 9] loss: 281.019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:02<00:00, 62.65it/s]\n",
      " 15%|█▌        | 2/13 [00:00<00:00, 17.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9] training acc: 0.529361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 24.25it/s]\n",
      "  4%|▍         | 6/144 [00:00<00:02, 59.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9] testing acc: 0.514286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:02<00:00, 59.89it/s]\n",
      "  5%|▍         | 7/144 [00:00<00:01, 69.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-30 14:00:40\t[epoch 10] loss: 267.970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:02<00:00, 62.63it/s]\n",
      " 15%|█▌        | 2/13 [00:00<00:00, 17.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10] training acc: 0.560244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 24.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10] testing acc: 0.541558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_from = 0\n",
    "if MODEL_PATH.find(\".pt\") != -1:\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "    p = MODEL_PATH.rfind('_')\n",
    "    train_from = int(MODEL_PATH[p+1 : -3])\n",
    "    MODEL_PATH = MODEL_PATH[: p-2]\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "timestamp(f\"start training {MODEL_PATH} from epoch {train_from+1} to {EPOCHS}\")\n",
    "for epoch in range(train_from, EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    for data in tqdm(trainLoader):\n",
    "        texts, labels = [t for t in data]\n",
    "\n",
    "        # 將參數梯度歸零\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(texts)\n",
    "        \n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss = loss_func(outputs.intent_cls, labels.to(device))\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 紀錄當前 batch loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "#     torch.save(model.state_dict(), F\"{MODEL_PATH}_E_{str(epoch+1)}.pt\")\n",
    "    timestamp(f\"[epoch {epoch+1}] loss: {running_loss:.3f}\")\n",
    "    writer.add_scalar('Loss/cls', running_loss, epoch)\n",
    "\n",
    "    _, acc = get_predictions(model, trainLoader, compute_acc=True)\n",
    "    print(f\"[epoch {epoch+1}] training acc: {acc:.6f}\")\n",
    "    writer.add_scalar('Acc/train', acc, epoch)\n",
    "\n",
    "    _, acc = get_predictions(model, testLoader, compute_acc=True)\n",
    "    print(f\"[epoch {epoch+1}] testing acc: {acc:.6f}\")\n",
    "    writer.add_scalar('Acc/test', acc, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11270d73",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187d91c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSet = intent_Dataset(\"test\", bert_test)\n",
    "testLoader = DataLoader(testSet, batch_size=BATCH_SIZE*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5c3287",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(1,2):\n",
    "    model.load_state_dict(torch.load(f\"{MODEL_PATH}_E_{e}.pt\"))\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    _, acc = get_predictions(model, testLoader, compute_acc=True)\n",
    "    print(f\"[epoch {e}] testing acc: {acc:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cdf5fee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 7])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(2, 5, 7)\n",
    "# With Learnable Parameters\n",
    "m = nn.LayerNorm(input.size()[1:])\n",
    "# Without Learnable Parameters\n",
    "# m = nn.LayerNorm(input.size()[1:], elementwise_affine=False)\n",
    "# Normalize over last two dimensions\n",
    "# m = nn.LayerNorm([10, 10])\n",
    "# Normalize over last dimension of size 10\n",
    "# m = nn.LayerNorm(7)\n",
    "# Activating the module\n",
    "output = m(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "daf20985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 7])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.size()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abf663c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
