{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "import jieba\n",
    "from ckiptagger import WS\n",
    "import ast\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"IVR\"\n",
    "WS_SET = [\"jieba\", \"ckip\", \"mix_0\", \"mix_1\"]\n",
    "WORD_SEGMENTER = WS_SET[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf(corpus, data):\n",
    "    with open(\"extend_dataset/IVR/tags.pkl\", 'rb') as fp:\n",
    "        tags = pickle.load(fp)\n",
    "\n",
    "    tf_list = []\n",
    "    for texts in corpus:\n",
    "        tf = [0] * len(tags)\n",
    "        for text in texts:\n",
    "            i = 0\n",
    "            for key, value in tags.items():\n",
    "                value = sorted(value, key=len, reverse=True)\n",
    "                value = [v for v in value if len(v)==len(text)]\n",
    "                if value == []:\n",
    "                    i += 1\n",
    "                    continue\n",
    "                big_regex = re.compile('|'.join(map(re.escape, value)))\n",
    "                temp = big_regex.findall(text)\n",
    "                tf[i] += len(temp)\n",
    "                i += 1\n",
    "        tf_list += [tf]\n",
    "    data[\"tf\"] = tf_list\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(test_tfidf, train_tfidf, num_labels=None):\n",
    "    if num_labels is None:\n",
    "        sim_array = cosine_similarity(test_tfidf, train_tfidf)\n",
    "    else:\n",
    "        train_tfidf_by_class = []\n",
    "        start_idx = 0\n",
    "        for i in num_labels:\n",
    "            train_tfidf_by_class += [train_tfidf[start_idx : start_idx+i].mean(axis=0)]\n",
    "            start_idx += i\n",
    "        train_tfidf_by_class = np.stack(train_tfidf_by_class)\n",
    "        sim_array = cosine_similarity(test_tfidf, train_tfidf_by_class)\n",
    "    \n",
    "    return np.array(sim_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(sim_array, test_data, train_data, sim_mode):\n",
    "    correct = 0\n",
    "    for i, ans in enumerate(test_data[\"label\"]):\n",
    "        if sim_mode == 0:\n",
    "            sorted_arg = np.argsort(sim_array[i])\n",
    "            sorted_arg = np.flip(sorted_arg)[:10] # 10 for top 10 similar\n",
    "            sorted_pred = [train_data[\"label\"][idx] for idx in sorted_arg]\n",
    "            pred = max(set(sorted_pred), key=sorted_pred.count)\n",
    "        else:\n",
    "            pred = np.argmax(sim_array[i])\n",
    "    \n",
    "        if pred == ans:\n",
    "            correct += 1\n",
    "    acc = correct / len(test_data[\"label\"])\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f0fb723e320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f0fb723e320>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f0f72ae82b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f0f72ae82b0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f0f772084e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f0f772084e0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f0f7964c668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f0f7964c668>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0f775025c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0f775025c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "if WORD_SEGMENTER == \"ckip\" or WORD_SEGMENTER.find(\"mix\") != -1:\n",
    "    ws = WS(\"../ckiptagger/data\")\n",
    "\n",
    "def get_model_data(file_path):\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "#     df = df.sort_values(by=[\"labels\"], ignore_index=True)\n",
    "    src_labels = sorted(set(df.labels.tolist()))\n",
    "    df[\"labels\"] = [src_labels.index(l) for l in df.labels.tolist()]\n",
    "    texts = df[\"texts\"]\n",
    "    labels = df[\"labels\"]\n",
    "    num_labels = list(Counter(labels).values())\n",
    "    \n",
    "    data = {\"corpus\":[], \"label\":[], \"src_texts\":[], \"src_label\":[]}\n",
    "    \n",
    "    for i, t in (enumerate(texts)):\n",
    "        label = labels[i]\n",
    "\n",
    "        if WORD_SEGMENTER == \"ckip\":\n",
    "            sentence_seg = ws([t])[0]\n",
    "        elif WORD_SEGMENTER == \"jieba\":\n",
    "            sentence_seg = jieba.lcut(t)\n",
    "        elif WORD_SEGMENTER == \"mix_0\":\n",
    "            temp = ws([t])[0]\n",
    "            sentence_seg = []\n",
    "            for seg_t in temp:\n",
    "                sentence_seg += jieba.lcut(seg_t)\n",
    "        elif WORD_SEGMENTER == \"mix_1\":\n",
    "            temp = jieba.lcut(t)\n",
    "            sentence_seg = []\n",
    "            for seg_t in temp:\n",
    "                sentence_seg += ws([seg_t])[0]\n",
    "    \n",
    "        sentence_seg = [seg_t for seg_t in sentence_seg if seg_t!=' ']\n",
    "#         seg_texts = ' '.join(sentence_seg)\n",
    "        \n",
    "        data[\"corpus\"] += [sentence_seg]\n",
    "        data[\"label\"] += [label]\n",
    "        data[\"src_texts\"] += [t]\n",
    "        data[\"src_label\"] += [src_labels[label]]\n",
    "    return data, num_labels # Dict[List], List[Int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, num_labels = get_model_data(f\"data/{DATASET}/train.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test, _ = get_model_data(f\"data/{DATASET}/test.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = get_tf(data_train[\"corpus\"], data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = get_tf(data_test[\"corpus\"], data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2144"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train[\"tf\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2144, 107)\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer(sublinear_tf=True)\n",
    "\n",
    "# df = pd.read_csv(f\"data/{DATASET}/train.tsv\", sep='\\t')\n",
    "# df.tf = df.tf.apply(ast.literal_eval)\n",
    "\n",
    "train_tf = np.stack(data_train[\"tf\"])\n",
    "train_tfidf = tfidf_transformer.fit_transform(train_tf)\n",
    "idf = tfidf_transformer.idf_\n",
    "# idf = np.ones(train_tfidf.shape[1])\n",
    "\n",
    "print(train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(548, 107)\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(f\"data/{DATASET}/test.tsv\", sep='\\t')\n",
    "# df.tf = df.tf.apply(ast.literal_eval)\n",
    "\n",
    "test_tf = np.stack(data_test[\"tf\"])\n",
    "test_tfidf = (np.ma.log(test_tf) + 1) * idf\n",
    "test_tfidf = test_tfidf.filled(0)\n",
    "\n",
    "test_tfidf = normalize(test_tfidf, norm='l2')\n",
    "print(test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(548, 2144)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6496350364963503"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SIM_MODE = 0\n",
    "sim_array = get_similarity(test_tfidf, train_tfidf)\n",
    "print(sim_array.shape)\n",
    "get_prediction(sim_array, data_test, data_train, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(548, 63)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0018248175182481751"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SIM_MODE = 1\n",
    "sim_array = get_similarity(test_tfidf, train_tfidf, num_labels)\n",
    "print(sim_array.shape)\n",
    "get_prediction(sim_array, data_test, data_train, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
